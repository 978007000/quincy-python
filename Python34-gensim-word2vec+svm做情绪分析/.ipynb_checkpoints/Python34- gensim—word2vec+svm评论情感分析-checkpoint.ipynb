{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim—word2vec+svm评论情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用gensim去做word2vec数据处理，使用sklearn做svm建模\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在京东买贵重物品放心，快还有保证，下次还会再来购买，给五星好评加分享，支持国货，没得说，小米手机性价比很高，满意加超赞！！  positive\n"
     ]
    }
   ],
   "source": [
    "#载入数据，做数据预处理（分词），切分训练集与测试集\n",
    "def load_file_and_preprocessing():\n",
    "    neg=pd.read_excel('data/neg.xls',header=None,index=None)\n",
    "    pos=pd.read_excel('data/pos.xls',header=None,index=None)\n",
    "\n",
    "    cw = lambda x: list(jieba.cut(x))\n",
    "\n",
    "    # 新增一列 word ,存放分好词的评论，pos[0]代表表格第一列\n",
    "\n",
    "    pos['words'] = pos[0].apply(cw)\n",
    "    neg['words'] = neg[0].apply(cw)\n",
    "\n",
    "    # np.ones(len(pos)) 新建一个长度为len(pos)的数组并初始化元素全为1来标注好评\n",
    "    # np.concatenate（）连接数组\n",
    "    # axis=0 向下执行方法 axis=1向右执行方法\n",
    "    y = np.concatenate((np.ones(len(pos)), np.zeros(len(neg))),axis=0)\n",
    "\n",
    "    # train_test_split：从样本中随机的按比例选取train data和testdata\n",
    "    # 一般形式：train_test_split(train_data,train_target,test_size=0.4, random_state=0)\n",
    "    # train_data：所要划分的样本特征集\n",
    "    # train_target：所要划分的样本结果（标注）\n",
    "    # test_size：样本占比，如果是整数的话就是样本的数量\n",
    "    # random_state：是随机数的种子。\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.concatenate((pos['words'], neg['words'])), y, test_size=0.2)\n",
    "    \n",
    "    np.save('svm_data/y_train.npy',y_train)\n",
    "    np.save('svm_data/y_test.npy',y_test)\n",
    "    return x_train,x_test\n",
    "\n",
    "\n",
    "\n",
    "# 对每个句子的所有词向量取均值，来生成一个句子的vector\n",
    "def build_sentence_vector(text, size,imdb_w2v):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += imdb_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "# 计算词向量\n",
    "def get_train_vecs(x_train, x_test):\n",
    "    n_dim = 300\n",
    "    # 初始化模型和词表\n",
    "    imdb_w2v = Word2Vec(x_train, size=n_dim, min_count=10)\n",
    "    # imdb_w2v = Word2Vec(size=300, window=5, min_count=10, workers=12)\n",
    "    # imdb_w2v.build_vocab(x_train)\n",
    "    #\n",
    "    # imdb_w2v.train(x_train,\n",
    "    #                total_examples=imdb_w2v.corpus_count,\n",
    "    #                epochs=imdb_w2v.iter)\n",
    "    \n",
    "\n",
    "    train_vecs = np.concatenate([build_sentence_vector(z, n_dim, imdb_w2v) for z in x_train])\n",
    "    # train_vecs = scale(train_vecs)\n",
    "\n",
    "    np.save('svm_data/train_vecs.npy', train_vecs)\n",
    "    print(train_vecs.shape) \n",
    "    # 在测试集上训练\n",
    "    imdb_w2v.train(x_test,total_examples=imdb_w2v.corpus_count,total_words=len(x_train),epochs=imdb_w2v.iter)\n",
    "    # imdb_w2v.train(x_test,\n",
    "    #                total_examples=imdb_w2v.corpus_count,\n",
    "    #                epochs=imdb_w2v.iter)\n",
    "\n",
    "    imdb_w2v.save('svm_data/w2v_model/w2v_model.pkl')\n",
    "    # Build test tweet vectors then scale\n",
    "    test_vecs = np.concatenate([build_sentence_vector(z, n_dim, imdb_w2v) for z in x_test])\n",
    "    # test_vecs = scale(test_vecs)\n",
    "    np.save('svm_data/test_vecs.npy', test_vecs)\n",
    "    print(test_vecs.shape) \n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    train_vecs=np.load('svm_data/train_vecs.npy')\n",
    "    y_train=np.load('svm_data/y_train.npy')\n",
    "    test_vecs=np.load('svm_data/test_vecs.npy')\n",
    "    y_test=np.load('svm_data/y_test.npy')\n",
    "    return train_vecs,y_train,test_vecs,y_test\n",
    "\n",
    "# 训练svm模型\n",
    "\n",
    "def svm_train(train_vecs,y_train,test_vecs,y_test):\n",
    "    clf=SVC(kernel='rbf',verbose=True)\n",
    "    clf.fit(train_vecs,y_train)\n",
    "    joblib.dump(clf, 'svm_data/svm_model/model.pkl')\n",
    "    print(clf.score(test_vecs,y_test)) \n",
    "\n",
    "\n",
    "# 构建待预测句子的向量\n",
    "\n",
    "def get_predict_vecs(words):\n",
    "    n_dim = 300\n",
    "    imdb_w2v = Word2Vec.load('svm_data/w2v_model/w2v_model.pkl')\n",
    "    #imdb_w2v.train(words)\n",
    "    train_vecs = build_sentence_vector(words, n_dim,imdb_w2v)\n",
    "    #print train_vecs.shape\n",
    "    return train_vecs\n",
    "\n",
    "# 对单个句子进行情感判断\n",
    "\n",
    "def svm_predict(string):\n",
    "    words=jieba.lcut(string)\n",
    "    words_vecs=get_predict_vecs(words)\n",
    "    clf=joblib.load('svm_data/svm_model/model.pkl')\n",
    "     \n",
    "    result=clf.predict(words_vecs)\n",
    "    \n",
    "    if int(result[0])==1:\n",
    "        print(string,' positive') \n",
    "    else:\n",
    "        print(string,' negative') \n",
    "\n",
    "#\n",
    "# x_train,x_test = load_file_and_preprocessing()\n",
    "# get_train_vecs(x_train,x_test)\n",
    "# train_vecs,y_train,test_vecs,y_test = get_data()\n",
    "# svm_train(train_vecs,y_train,test_vecs,y_test)\n",
    "\n",
    "#对输入句子情感进行判断\n",
    "# string='电池充完了电连手机都打不开.简直烂的要命.真是金玉其外,败絮其中!连5号电池都不如'\n",
    "# string='这手机真棒，从1米高的地方摔下去就坏了'\n",
    "# string=\"我今天买了一台电脑，刚用一会电池就没电了，建议大家不要买\"\n",
    "# string=\"这个手机很好了，续航时间特别长\"\n",
    "# string=\"我的电脑花了7000元，配置很好，但是用了几天坏了，很热，不便捷\"\n",
    "# string=\"本来拍了几张图片分享下的，京东把晒单驳回了！一个差评就这样做！唉\"\n",
    "# string=\"手机发热厉害，昨天直接充不进电了！！！我为啥要买这个*破*手机啊？\"\n",
    "string=\"手机反应速度快，价格便宜，照相也很清楚，玩游戏也不卡，外观漂亮，物美价廉，！\"\n",
    "string=\"在京东买贵重物品放心，快还有保证，下次还会再来购买，给五星好评加分享，支持国货，没得说，小米手机性价比很高，满意加超赞！！\"\n",
    "svm_predict(string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
