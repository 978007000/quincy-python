{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Google的自驾车和机器人得到了很多新闻，但公司的真正未来是机器学习，这种技术使计算机变得更智能，更个性化。`\n",
    "\n",
    "                                                                          -Eric Schmidt (Google Chairman)\n",
    "---                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可能生活在人类历史上最具影响力的时期——计算从大型主机到PC移动到云计算的时期。 但是使这段时期有意义的不是发生了什么，而是在未来几年里我们的方式。\n",
    "\n",
    "这个时期令像我这样的一个人兴奋的就是，随着计算机的推动，工具和技术的民主化。 今天，作为数据科学家，我可以每小时为几个玩偶构建具有复杂算法的数据处理机。 但到达这里并不容易，我已经度过了许多黑暗的日日夜夜。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 谁可以从本指南中获益最多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>我今天发布的可能是我创造的最有价值的指南。</strong>\n",
    "\n",
    "创建本指南背后的理念是简化全球有抱负的数据科学家和机器学习爱好者的旅程。 本指南能够使你在研究机器学习问题的过程中获取经验。 我提供了关于各种机器学习算法以及R＆Python代码的高级理解以及运行它们，这些应该足以使你得心顺手。\n",
    "![machine learning](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/Newl-Machine-Learning-Algorithms.jpg)\n",
    "我故意跳过了这些技术背后的统计数据，因为你不需要在开始时就了解它们。 所以，如果你正在寻找对这些算法的统计学理解，你应该看看别的文章。 但是，如果你正在寻找并开始构建机器学习项目，那么这篇文章给你带来极大好处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3类机器学习算法（广义上）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 监督学习\n",
    "工作原理：该算法由一组目标/结果变量（或因变量）组成，该变量将根据给定的一组预测变量（独立变量）进行预测。 使用这些变量集，我们生成一个将输入映射到所需输出的函数。 训练过程继续进行执行，直到模型达到培训数据所需的准确度水平。 监督学习的例子：回归，决策树，随机森林，KNN，逻辑回归等\n",
    "\n",
    "2. 无监督学习\n",
    "如何工作：在这个算法中，我们没有任何目标或结果变量来预测/估计。 用于不同群体的群体聚类和用于不同群体的客户进行特定干预。 无监督学习的例子：Apriori算法，K-means。\n",
    "\n",
    "3. 加强学习：\n",
    "工作原理：使用这种算法，机器受到学习和训练，作出具体决定。 它以这种方式工作：机器暴露在一个环境中，它连续不断地使用试错。 该机器从过去的经验中学习，并尝试捕获最好的知识，以做出准确的业务决策。 加强学习示例：马尔可夫决策过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常见机器学习算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是常用机器学习算法的列表。 这些算法几乎可以应用于任何数据问题：\n",
    "\n",
    "- 线性回归\n",
    "- 逻辑回归\n",
    "- 决策树\n",
    "- SVM\n",
    "- 朴素贝叶斯\n",
    "- KNN\n",
    "- K均值\n",
    "- 随机森林\n",
    "- 降维算法\n",
    "- Gradient Boost＆Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它用于基于连续变量来估计实际价值（房屋成本，电话数量，总销售额等）。在这里，我们通过拟合最佳线来建立独立变量和因变量之间的关系。这个最佳拟合线被称为回归线，由线性方程`Y = a * X + b`表示。\n",
    "\n",
    "理解线性回归的最好方法是回想童年的经历。比如，你要求五年级的孩子通过体重来从小到大排序班里的学生，而事先不告诉学生们的体重！你认为孩子会做什么？他/她很可能在身高和体格上分析人物的体重，并使用这些可视参数的组合进行排列。这是现实生活中的线性回归！孩子实际上已经弄清楚，身高和体格将有一个关系与体重相关联，看起来就像上面的等式。\n",
    "\n",
    "在这个方程式中：\n",
    "\n",
    "`Y-因变量`\n",
    "`a - 斜率`\n",
    "`X - 自变量`\n",
    "`b - 截距`\n",
    "这些系数a和b是基于最小化数据点和回归线之间的距离的平方差之和导出的。\n",
    "\n",
    "看下面的例子。这里我们确定了线性方程`y = 0.2811x + 13.9`的最佳拟合线。现在使用这个方程，我们可以找到一个人（身高已知）的体重。\n",
    "![线性回归](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/Linear_Regression.png)\n",
    "线性回归主要有两种类型：简单线性回归和多元线性回归。 简单线性回归的特征在于一个自变量。 而且，多元线性回归（顾名思义）的特征是多个（多于1个）自变量。 在找到最佳拟合线的同时，可以拟合多项式或曲线回归线，这些被称为多项式或曲线回归。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98267731  0.23364069  0.35133775  0.92826309]\n",
      " [ 0.80538991  0.05637806  0.87662175  0.3960776 ]\n",
      " [ 0.54686738  0.6816495   0.99747716  0.32531085]\n",
      " [ 0.19189509  0.87105462  0.88158122  0.25056621]]\n",
      "[[ 0.55541608  0.56859636  0.40616234  0.14683524]\n",
      " [ 0.09937835  0.63874553  0.92062536  0.32798326]\n",
      " [ 0.87174236  0.779044    0.79119392  0.06912842]\n",
      " [ 0.87907434  0.53175367  0.01371655  0.11414196]]\n",
      "[[ 0.37568516  0.17267374  0.51647046  0.04774661]\n",
      " [ 0.38573914  0.85335136  0.11647555  0.0758696 ]\n",
      " [ 0.67559384  0.57535368  0.88579261  0.26278658]\n",
      " [ 0.13829782  0.28328756  0.51170484  0.04260013]]\n",
      "Coefficient: \n",
      " [[ 0.55158868  1.45901817  0.31224322  0.49538173]\n",
      " [ 0.6995448   0.40804135  0.59938423  0.09084578]\n",
      " [ 1.79010371  0.21674532  1.60972012 -0.046387  ]\n",
      " [-0.31562917 -0.53767439 -0.16141312 -0.2154683 ]]\n",
      "Intercept: \n",
      " [-0.89705102 -0.50908061 -1.9260686   0.83934127]\n",
      "predicted:\n",
      " [[-0.25297601  0.13808785 -0.38696891  0.53426883]\n",
      " [ 0.63472658  0.18566989 -0.86662193  0.22361739]\n",
      " [ 0.72181277  0.75309881  0.82170796  0.11715048]\n",
      " [-0.22656611  0.01383581 -0.79537442  0.55159912]]\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "#Import other necessary libraries like pandas, numpy...\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "#Load Train and Test datasets\n",
    "#Identify feature and response variable(s) and values must be numeric and numpy arrays\n",
    "# x_train=input_variables_values_training_datasets\n",
    "x_train=np.random.rand(4,4)\n",
    "print(x_train)\n",
    "# y_train=target_variables_values_training_datasets\n",
    "y_train=np.random.rand(4,4)\n",
    "print(y_train)\n",
    "\n",
    "# x_test=input_variables_values_test_datasets\n",
    "x_test=np.random.rand(4,4)\n",
    "print(x_test)\n",
    "\n",
    "# Create linear regression object\n",
    "linear = linear_model.LinearRegression()\n",
    "# Train the model using the training sets and check score\n",
    "linear.fit(x_train, y_train)\n",
    "linear.score(x_train, y_train)\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', linear.coef_)\n",
    "print('Intercept: \\n', linear.intercept_)\n",
    "#Predict Output\n",
    "predicted= linear.predict(x_test)\n",
    "print('predicted:\\n',predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Train and Test datasets\n",
    "#Identify feature and response variable(s) and values must be numeric and numpy arrays\n",
    "x_train <- input_variables_values_training_datasets\n",
    "y_train <- target_variables_values_training_datasets\n",
    "x_test <- input_variables_values_test_datasets\n",
    "x <- cbind(x_train,y_train)\n",
    "# Train the model using the training sets and check score\n",
    "linear <- lm(y_train ~ ., data = x)\n",
    "summary(linear)\n",
    "#Predict Output\n",
    "predicted= predict(linear,x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要因为它的名字而感到困惑，逻辑回归是一个分类算法而不是回归算法。它用于基于给定的一组自变量来估计离散值（二进制值，如0/1，是/否，真/假）。简单来说，它通过将数据拟合到logit函数来预测事件发生的概率。因此，它也被称为logit回归。由于它预测概率，其输出值在0和1之间（如预期的那样）。\n",
    "\n",
    "再次，让我们通过一个简单的例子来尝试理解这一点。\n",
    "\n",
    "假设你的朋友给你一个难题解决。只有2个结果场景 - 你能解决和不能解决。现在想象，你正在被许多猜谜或者简单测验，来试图理解你擅长的科目。这项研究的结果将是这样的结果 - 如果给你一个10级的三角形问题，那么你有70％可能会解决这个问题。另外一个例子，如果是五级的历史问题，得到答案的概率只有30％。这就是逻辑回归为你提供的结果。\n",
    "\n",
    "对数学而言，结果的对数几率被建模为预测变量的线性组合。\n",
    "\n",
    "`odds= p/ (1-p) = probability of event occurrence / probability of not event occurrence\n",
    "ln(odds) = ln(p/(1-p))\n",
    "logit(p) = ln(p/(1-p)) = b0+b1X1+b2X2+b3X3....+bkXk`\n",
    "\n",
    "以上，p是感兴趣特征的概率。 它选择最大化观察样本值的可能性的参数，而不是最小化平方误差的总和（如在普通回归中）。\n",
    "\n",
    "现在，你可能会问，为什么要采用log？ 为了简单起见，让我们来说，这是复制阶梯函数的最好的数学方法之一。 我可以进一步详细介绍，但这将会打破这篇文章的目的。\n",
    "![逻辑回归](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/Logistic_Regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create logistic regression object\n",
    "model = LogisticRegression()\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', model.coef_)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
